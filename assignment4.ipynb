{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alvin Jin\n",
    "Student ID: 027152786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.706\n",
      "Confusion Matrix:\n",
      "                   Predicted:\n",
      "                   Bad        Good\n",
      "___________________________________\n",
      "Actual:   Bad    | 32         268\n",
      "          Good   | 26         674\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# set y as labels\n",
    "# set x as features\n",
    "\n",
    "# returns the dot product and the matrix transposed\n",
    "def model(x, w):\n",
    "    a = np.dot(x.T, w)\n",
    "    return a.T\n",
    "\n",
    "# define sigmoid function\n",
    "def sigmoid(t):\n",
    "    return 1/(1+ np.exp(-t))\n",
    "\n",
    "#softmax cost function\n",
    "def gradient(x, y, w):\n",
    "    S = sigmoid(-y * model(x, w))\n",
    "    gradient = -np.dot(x, (S * y).T)\n",
    "    return gradient\n",
    "\n",
    "#creates the gradient descent\n",
    "def gradientDescent(x, y):\n",
    "    #alpha being learning rate\n",
    "    alpha = 0.0000000001\n",
    "    #k being the iteration\n",
    "    k = 50000\n",
    "    #controls the randomness generated for w\n",
    "    np.random.seed(0)\n",
    "    #extracts the first row of x the geatures\n",
    "    features = x.shape[0]  \n",
    "    #generates random weights from -0.05 to 0.05, the matrix shape being (features, 1) or (21, 1)\n",
    "    w = np.random.uniform(-0.05, 0.05, size = (features, 1))  \n",
    "    for _ in range(k):\n",
    "        #grabs gradient from the function (21, 1)\n",
    "        grad = gradient(x, y, w)\n",
    "        #update w(21, 1)\n",
    "        w = w - alpha * grad\n",
    "    return w\n",
    "\n",
    "#Make predictions\n",
    "def predict(x, w):\n",
    "    #w and x have to be transposed to get dot product\n",
    "    probability = sigmoid(np.dot(x.T, w.T))\n",
    "    #creates an array full of 1s and -1s\n",
    "    #1 if the probability is greater than or equal to 0.5, -1 if the probability is less than 0.5\n",
    "    predictionArr = np.where(probability >= 0.5, 1, -1)\n",
    "    return predictionArr\n",
    "\n",
    "#create confusion matrix\n",
    "def confusion_matrix(yTrue, yPred):\n",
    "    #calculates the amount for tp, tn, fp, fn respectfully\n",
    "    tp = np.sum(np.logical_and(yTrue == 1, yPred == 1))\n",
    "    tn = np.sum(np.logical_and(yTrue == -1, yPred == -1))\n",
    "    fp = np.sum(np.logical_and(yTrue == -1, yPred == 1))\n",
    "    fn = np.sum(np.logical_and(yTrue == 1, yPred == -1))\n",
    "    #returns a matrix/2d array based on those values\n",
    "    return np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "#finds the accuracy\n",
    "def accuracy(yTrue, yPred):\n",
    "    #finds the sum of true positive and negative\n",
    "    #returns the accuracy which is sum of tp and tn divided by total amount\n",
    "    return float(np.sum(yTrue == yPred) / len(yTrue))\n",
    "\n",
    "#initalize csv file name\n",
    "csvname = 'credit_dataset.csv'\n",
    "#load the csv file\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "# feature values\n",
    "xData = data[:-1,:]\n",
    "yData = data[-1:,:]\n",
    "# Convert them to numpy arrays\n",
    "x = np.array(xData)\n",
    "y = np.array(yData)\n",
    "# adding Bias to the points\n",
    "x = np.row_stack([np.ones(x.shape[1]), x])\n",
    "\n",
    "#find the optimal weight or w\n",
    "minW = gradientDescent(x, y)\n",
    "\n",
    "# divide datasets into train and test sets(80% for train , 20% for test)\n",
    "#use xTest and yTest for functions predict, confusion matrix, and accuracy\n",
    "trainIndex = int(0.8 * len(y))\n",
    "xTest = x[trainIndex:]\n",
    "yTest = y[trainIndex:]\n",
    "\n",
    "#returns the prediction array, similar to perceptron\n",
    "#reshape(-1) flattens 2d array to 1d array\n",
    "yPred = predict(minW, xTest.T).reshape(-1)\n",
    "yTestFlat= yTest.reshape(-1)\n",
    "#return conMatrix\n",
    "conMatrix = confusion_matrix(yTestFlat, yPred)\n",
    "#return accuracy\n",
    "ac = accuracy(yTestFlat, yPred)\n",
    "\n",
    "#display accuracy\n",
    "print(\"Accuracy:\", ac)\n",
    "# print(conMatrix)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"                   Predicted:\")\n",
    "print(\"                   Bad        Good\")\n",
    "print(\"___________________________________\")\n",
    "#extract tn, fp, fn, tp from the confusion matrix for output\n",
    "print(\"Actual:   Bad    |\", conMatrix[0][0], \"       \", conMatrix[0][1])\n",
    "print(\"          Good   |\", conMatrix[1][0], \"       \", conMatrix[1][1] )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
